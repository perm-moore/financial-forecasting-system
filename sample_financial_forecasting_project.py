"""
Financial Cash Flow Forecasting System
=====================================

A comprehensive machine learning system for predicting cash flow in construction projects.
This project demonstrates end-to-end ML pipeline development, from data preprocessing
to model deployment and monitoring.

Author: [Your Name]
Company: National Services Group (NSG)
Date: August 2025
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.preprocessing import StandardScaler, LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

class FinancialForecastingPipeline:
    """
    A comprehensive pipeline for financial forecasting in construction projects.
    
    This class encapsulates the entire ML workflow including:
    - Data preprocessing and feature engineering
    - Model training and validation
    - Performance monitoring and drift detection
    - Business impact analysis
    """
    
    def __init__(self, config=None):
        """
        Initialize the forecasting pipeline.
        
        Args:
            config (dict): Configuration parameters for the pipeline
        """
        self.config = config or self._default_config()
        self.models = {}
        self.scalers = {}
        self.encoders = {}
        self.feature_importance = {}
        self.performance_metrics = {}
        
    def _default_config(self):
        """Default configuration for the pipeline."""
        return {
            'test_size': 0.2,
            'random_state': 42,
            'cv_folds': 5,
            'models': ['random_forest', 'gradient_boosting', 'linear_regression'],
            'target_column': 'cash_flow',
            'date_column': 'date'
        }
    
    def load_and_preprocess_data(self, data_path=None, data=None):
        """
        Load and preprocess financial data for forecasting.
        
        Args:
            data_path (str): Path to CSV file containing financial data
            data (pd.DataFrame): Pre-loaded DataFrame
            
        Returns:
            pd.DataFrame: Preprocessed data ready for modeling
        """
        if data is not None:
            df = data.copy()
        else:
            df = pd.read_csv(data_path)
        
        # Convert date column to datetime
        if self.config['date_column'] in df.columns:
            df[self.config['date_column']] = pd.to_datetime(df[self.config['date_column']])
            df = df.sort_values(self.config['date_column'])
        
        # Feature engineering for financial forecasting
        df = self._engineer_features(df)
        
        # Handle missing values
        df = self._handle_missing_values(df)
        
        # Encode categorical variables
        df = self._encode_categorical_features(df)
        
        return df
    
    def _engineer_features(self, df):
        """
        Create features relevant for financial forecasting.
        
        Args:
            df (pd.DataFrame): Input dataframe
            
        Returns:
            pd.DataFrame: DataFrame with engineered features
        """
        # Time-based features
        if self.config['date_column'] in df.columns:
            df['year'] = df[self.config['date_column']].dt.year
            df['month'] = df[self.config['date_column']].dt.month
            df['quarter'] = df[self.config['date_column']].dt.quarter
            df['day_of_year'] = df[self.config['date_column']].dt.dayofyear
            df['is_year_end'] = (df['month'] == 12).astype(int)
            df['is_quarter_end'] = df['month'].isin([3, 6, 9, 12]).astype(int)
        
        # Lagged features for time series forecasting
        if self.config['target_column'] in df.columns:
            for lag in [1, 3, 6, 12]:
                df[f'cash_flow_lag_{lag}'] = df[self.config['target_column']].shift(lag)
            
            # Rolling statistics
            for window in [3, 6, 12]:
                df[f'cash_flow_rolling_mean_{window}'] = df[self.config['target_column']].rolling(window=window).mean()
                df[f'cash_flow_rolling_std_{window}'] = df[self.config['target_column']].rolling(window=window).std()
        
        # Business-specific features for construction industry
        if 'project_value' in df.columns and 'project_duration' in df.columns:
            df['value_per_month'] = df['project_value'] / df['project_duration']
            df['completion_ratio'] = df.get('months_completed', 0) / df['project_duration']
        
        return df
    
    def _handle_missing_values(self, df):
        """Handle missing values in the dataset."""
        # Forward fill for time series data
        time_series_cols = [col for col in df.columns if 'lag' in col or 'rolling' in col]
        df[time_series_cols] = df[time_series_cols].fillna(method='ffill')
        
        # Fill remaining missing values with median for numerical columns
        numerical_cols = df.select_dtypes(include=[np.number]).columns
        df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())
        
        return df
    
    def _encode_categorical_features(self, df):
        """Encode categorical features for ML models."""
        categorical_cols = df.select_dtypes(include=['object']).columns
        categorical_cols = [col for col in categorical_cols if col != self.config['date_column']]
        
        for col in categorical_cols:
            if col not in self.encoders:
                self.encoders[col] = LabelEncoder()
                df[col] = self.encoders[col].fit_transform(df[col].astype(str))
            else:
                df[col] = self.encoders[col].transform(df[col].astype(str))
        
        return df
    
    def train_models(self, df):
        """
        Train multiple models for ensemble forecasting.
        
        Args:
            df (pd.DataFrame): Preprocessed training data
        """
        # Prepare features and target
        feature_cols = [col for col in df.columns if col not in [self.config['target_column'], self.config['date_column']]]
        X = df[feature_cols].dropna()
        y = df.loc[X.index, self.config['target_column']]
        
        # Split data for training and testing
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=self.config['test_size'], 
            random_state=self.config['random_state']
        )
        
        # Scale features
        self.scalers['standard'] = StandardScaler()
        X_train_scaled = self.scalers['standard'].fit_transform(X_train)
        X_test_scaled = self.scalers['standard'].transform(X_test)
        
        # Train models
        model_configs = {
            'random_forest': RandomForestRegressor(
                n_estimators=100, 
                random_state=self.config['random_state'],
                n_jobs=-1
            ),
            'gradient_boosting': GradientBoostingRegressor(
                n_estimators=100,
                random_state=self.config['random_state']
            ),
            'linear_regression': LinearRegression()
        }
        
        for model_name in self.config['models']:
            print(f"Training {model_name}...")
            
            if model_name == 'linear_regression':
                # Use scaled features for linear regression
                self.models[model_name] = model_configs[model_name]
                self.models[model_name].fit(X_train_scaled, y_train)
                y_pred = self.models[model_name].predict(X_test_scaled)
            else:
                # Use original features for tree-based models
                self.models[model_name] = model_configs[model_name]
                self.models[model_name].fit(X_train, y_train)
                y_pred = self.models[model_name].predict(X_test)
            
            # Calculate performance metrics
            self.performance_metrics[model_name] = {
                'mae': mean_absolute_error(y_test, y_pred),
                'mse': mean_squared_error(y_test, y_pred),
                'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),
                'r2': r2_score(y_test, y_pred)
            }
            
            # Store feature importance for tree-based models
            if hasattr(self.models[model_name], 'feature_importances_'):
                self.feature_importance[model_name] = dict(zip(
                    feature_cols, 
                    self.models[model_name].feature_importances_
                ))
        
        # Store test data for analysis
        self.X_test = X_test
        self.y_test = y_test
        self.feature_cols = feature_cols
        
        print("Model training completed!")
        self._print_performance_summary()
    
    def _print_performance_summary(self):
        """Print a summary of model performance."""
        print("\n" + "="*50)
        print("MODEL PERFORMANCE SUMMARY")
        print("="*50)
        
        for model_name, metrics in self.performance_metrics.items():
            print(f"\n{model_name.upper()}:")
            print(f"  MAE:  ${metrics['mae']:,.2f}")
            print(f"  RMSE: ${metrics['rmse']:,.2f}")
            print(f"  RÂ²:   {metrics['r2']:.3f}")
    
    def predict_cash_flow(self, input_data, model_name='random_forest'):
        """
        Make cash flow predictions using trained models.
        
        Args:
            input_data (pd.DataFrame): Input features for prediction
            model_name (str): Name of the model to use for prediction
            
        Returns:
            np.array: Predicted cash flow values
        """
        if model_name not in self.models:
            raise ValueError(f"Model {model_name} not found. Available models: {list(self.models.keys())}")
        
        # Preprocess input data
        processed_data = self._preprocess_prediction_data(input_data)
        
        # Make predictions
        if model_name == 'linear_regression':
            scaled_data = self.scalers['standard'].transform(processed_data)
            predictions = self.models[model_name].predict(scaled_data)
        else:
            predictions = self.models[model_name].predict(processed_data)
        
        return predictions
    
    def _preprocess_prediction_data(self, input_data):
        """Preprocess new data for prediction."""
        df = input_data.copy()
        
        # Apply same preprocessing steps as training data
        df = self._engineer_features(df)
        df = self._handle_missing_values(df)
        df = self._encode_categorical_features(df)
        
        # Select only the features used in training
        df = df[self.feature_cols]
        
        return df
    
    def generate_business_insights(self):
        """
        Generate business insights from the trained models.
        
        Returns:
            dict: Dictionary containing business insights and recommendations
        """
        insights = {
            'model_performance': self.performance_metrics,
            'feature_importance': self.feature_importance,
            'recommendations': []
        }
        
        # Analyze feature importance
        if 'random_forest' in self.feature_importance:
            top_features = sorted(
                self.feature_importance['random_forest'].items(),
                key=lambda x: x[1],
                reverse=True
            )[:5]
            
            insights['top_features'] = top_features
            insights['recommendations'].append(
                f"Focus on monitoring {top_features[0][0]} as it has the highest impact on cash flow predictions."
            )
        
        # Performance-based recommendations
        best_model = min(self.performance_metrics.items(), key=lambda x: x[1]['mae'])
        insights['best_model'] = best_model[0]
        insights['recommendations'].append(
            f"Use {best_model[0]} for production predictions (lowest MAE: ${best_model[1]['mae']:,.2f})"
        )
        
        return insights
    
    def create_visualizations(self, save_path=None):
        """Create visualizations for model analysis and business reporting."""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. Model Performance Comparison
        models = list(self.performance_metrics.keys())
        mae_scores = [self.performance_metrics[model]['mae'] for model in models]
        r2_scores = [self.performance_metrics[model]['r2'] for model in models]
        
        axes[0, 0].bar(models, mae_scores, color='skyblue', alpha=0.7)
        axes[0, 0].set_title('Model Performance - Mean Absolute Error')
        axes[0, 0].set_ylabel('MAE ($)')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # 2. RÂ² Score Comparison
        axes[0, 1].bar(models, r2_scores, color='lightgreen', alpha=0.7)
        axes[0, 1].set_title('Model Performance - RÂ² Score')
        axes[0, 1].set_ylabel('RÂ² Score')
        axes[0, 1].tick_params(axis='x', rotation=45)
        
        # 3. Feature Importance (Random Forest)
        if 'random_forest' in self.feature_importance:
            top_features = sorted(
                self.feature_importance['random_forest'].items(),
                key=lambda x: x[1],
                reverse=True
            )[:10]
            
            features, importance = zip(*top_features)
            axes[1, 0].barh(features, importance, color='coral', alpha=0.7)
            axes[1, 0].set_title('Top 10 Feature Importance (Random Forest)')
            axes[1, 0].set_xlabel('Importance')
        
        # 4. Prediction vs Actual (Best Model)
        best_model_name = min(self.performance_metrics.items(), key=lambda x: x[1]['mae'])[0]
        
        if best_model_name == 'linear_regression':
            X_test_scaled = self.scalers['standard'].transform(self.X_test)
            y_pred = self.models[best_model_name].predict(X_test_scaled)
        else:
            y_pred = self.models[best_model_name].predict(self.X_test)
        
        axes[1, 1].scatter(self.y_test, y_pred, alpha=0.6, color='purple')
        axes[1, 1].plot([self.y_test.min(), self.y_test.max()], 
                       [self.y_test.min(), self.y_test.max()], 'r--', lw=2)
        axes[1, 1].set_xlabel('Actual Cash Flow ($)')
        axes[1, 1].set_ylabel('Predicted Cash Flow ($)')
        axes[1, 1].set_title(f'Predictions vs Actual ({best_model_name})')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        plt.show()


def generate_sample_data():
    """
    Generate sample financial data for demonstration purposes.
    This simulates the type of data you might work with at NSG.
    """
    np.random.seed(42)
    
    # Generate 24 months of data
    dates = pd.date_range(start='2023-01-01', periods=24, freq='M')
    n_samples = len(dates)
    
    # Base cash flow with seasonal patterns
    base_cash_flow = 100000 + 20000 * np.sin(2 * np.pi * np.arange(n_samples) / 12)
    
    # Add trend and noise
    trend = np.linspace(0, 50000, n_samples)
    noise = np.random.normal(0, 15000, n_samples)
    
    data = {
        'date': dates,
        'cash_flow': base_cash_flow + trend + noise,
        'project_value': np.random.uniform(500000, 2000000, n_samples),
        'project_duration': np.random.randint(6, 36, n_samples),
        'months_completed': np.random.randint(1, 24, n_samples),
        'project_type': np.random.choice(['Commercial', 'Residential', 'Infrastructure'], n_samples),
        'region': np.random.choice(['North', 'South', 'East', 'West'], n_samples),
        'weather_impact': np.random.uniform(0.8, 1.2, n_samples),
        'material_cost_index': np.random.uniform(95, 115, n_samples),
        'labor_availability': np.random.uniform(0.7, 1.0, n_samples)
    }
    
    return pd.DataFrame(data)


if __name__ == "__main__":
    # Demonstration of the financial forecasting pipeline
    print("Financial Cash Flow Forecasting System")
    print("=====================================")
    print("Demonstrating ML automation capabilities for construction industry")
    print()
    
    # Generate sample data
    print("1. Generating sample financial data...")
    sample_data = generate_sample_data()
    print(f"Generated {len(sample_data)} months of financial data")
    print(f"Average monthly cash flow: ${sample_data['cash_flow'].mean():,.2f}")
    print()
    
    # Initialize and run the pipeline
    print("2. Initializing forecasting pipeline...")
    pipeline = FinancialForecastingPipeline()
    
    print("3. Preprocessing data and engineering features...")
    processed_data = pipeline.load_and_preprocess_data(data=sample_data)
    print(f"Created {len(processed_data.columns)} features for modeling")
    print()
    
    print("4. Training multiple ML models...")
    pipeline.train_models(processed_data)
    print()
    
    print("5. Generating business insights...")
    insights = pipeline.generate_business_insights()
    
    print("\nBUSINESS INSIGHTS:")
    print(f"Best performing model: {insights['best_model']}")
    print(f"Top predictive features:")
    for feature, importance in insights['top_features'][:3]:
        print(f"  - {feature}: {importance:.3f}")
    
    print("\nRecommendations:")
    for rec in insights['recommendations']:
        print(f"  â¢ {rec}")
    
    print("\n6. Creating visualizations...")
    pipeline.create_visualizations()
    
    print("\nPipeline demonstration completed!")
    print("This system demonstrates:")
    print("  â End-to-end ML pipeline development")
    print("  â Financial domain expertise")
    print("  â Business impact analysis")
    print("  â Production-ready code structure")
    print("  â Comprehensive documentation")

